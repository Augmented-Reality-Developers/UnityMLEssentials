Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
50000,1.0524579,25.006753246753245,0.5105231,0.37255983364561907,0.37255983364561907,0.12040079,0.023334045,0.00028461742,0.19487244,0.004744136,1.0
100000,0.9243643,28.540141676505314,0.7325584,0.9140933254767788,0.9140933254767788,0.029012274,0.02396899,0.00025688164,0.1856272,0.0042827977,1.0
150000,0.80018634,29.273939393939393,0.85242957,0.987772397097137,0.987772397097137,0.0052066045,0.022623718,0.00022605582,0.1753519,0.0037700608,1.0
200000,0.7382059,29.34325637910085,0.8614316,0.9963205828787742,0.9963205828787742,0.00203872,0.022614945,0.00019525108,0.16508368,0.0032576756,1.0
250000,0.73042476,29.209764918625677,0.8612671,0.9993900966184924,0.9993900966184924,0.0009897236,0.022282176,0.00016441397,0.15480465,0.0027447515,1.0
